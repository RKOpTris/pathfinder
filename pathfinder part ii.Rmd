---
title: 'pathfinder: an algorithm for finding the most efficient path between waypoints - Part II - Being less stupid'
author: "RKOpTris"
date: '2024-04-21'
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Abstract

This is a continuation of a journey to write an algorithm from scratch which finds the most efficient path between a set of waypoints with a variety of paths between them. (I'm adding to this document intermittently and iteratively and represents a work in progress.)

Welcome to Part Deux!

## Introduction

In the first part of this series we wrote a not-so-clever algorithm to find the shortest distance from a start/finish waypoint that passed through a group of other waypoints at least once. It managed it but did not find the best route, nor did it do it very quickly. Here we explore how we can improve upon our original design.

### Methods and R code

Firstly, let's load in the needed libraries and the functions we defined in the Part I.

```{r, initial_funs}
library(dplyr)
library(stringr)
source("generate_points.R")
source("generate_paths.R")
source("get_pos.R")
source("visualise_paths.R")
source("get_distance.R")
source("init_points.R")
source("init_paths.R")
source("error_code_for_plot.R")
source("error_code_summary.R")
source("fail_run.R")
source("find_path.R")
source("get_path_length.R")
source("get_path.R")
source("plot_error_codes.R")
source("plot_path.R")
source("report_success.R")
source("reset_global_vars.R")
source("reset_run_vars.R")
source("str_to_waypoints.R")
source("waypoints_to_str.R")
source("succeed_run.R")
source("withSeed.R")
```

Our model in Part I succeeded in finding a reasonably efficient route with a distance of 16.2. That is, however, not the best route which comes in under 16. Further, it took 1.5 minutes to complete using all the time available to it (defined by that maximum number of runs). We also saw the main reason for failure initially was that waypoints were being visited too many times (which is set as a default of 3 in the global vars environment and had an error code of F-MW). This error code gradually changed too "F-XD" denoting that the maximum-allowed distance had been reached. The maximum-allowed distance is set iteratively, which each start-finish success needing to find an equivalent or shorter route. It makes sense then that the model fails more often as the maximum-allowed route gets shorter.

To make the algorithm a bit more discerning we can introduce the idea of a penalty that is imposed on a waypoint when it has been visited. To do this, all waypoints are assigned a probability that they will be selected as the next waypoint. In statistical fields, this is known as weighting. In this example, each waypoint starts with a penalty of 1 in all cases, and so from $A$ if connected points $B$ and $C$ have an equal probability, then the likelihood the of the algorithm travelling to either of them is equal. Because the algorithm has been at $A$, we will impose a multiplier of 0.25 (an arbitrary penalty), so 1 * 0.25 = 0.25. When the algorithm moves to $B$ that same penalty is incurred. Now, if $B$ connects to $C$ and $D$, and also to $A$, $C$ and $D$ have no penalty, 1, but as waypoint $A$ has a penalty imposed, it will be less probably that the algorithm will select that waypoint. So it moves to $C$ or $D$ and the process is continued. If equal penalties have been imposed on all waypoint choices from any given point, then the probability of choosing any particular waypoint to move to is equal again.

In this way we keep the algorithm moving, rather than allowing it to "dither"; moving needlessly between points it has already visited. As we saw from the error codes and the paths is took, we can see that this was an issue.

With this more efficient method of choosing waypoints/paths we can expect that the algorithm might find an efficient route fasterr and it may not be necessary to continue to the maximum number of allowed runs. At the moment, the model reports the distance it has taken, if it is equal to or less than the record previously set. As such we will apply a conservative cut-off so that if the model fails to improve 3 times, then we can assume one of the most efficient, or the most efficient path has been discovered.

So let's update the pseudocode from the Part I:

```{r, eval=FALSE}
while a predefined maximum number of runs has not ben reached *or* the last 3 (best) distances 
are all the same:
  
  attempt by random choice to get from start/finish waypoint by visiting all other 
  waypoints at least once, not exceeding the maximum allowed distance and not
  exceeding the maximum number of visits for each waypoint
  
  before moving apply any probabalistic penalty to any potential paths available 
  
  for each visited waypoint apply a probabistic penalty
  
    if success:
      set distance travelled as the maximum allowed distance for further loops 
      report success
      reset the run
    else if fail:
      report reason for failure
      reset the run
```

Let's see how these changes have affected the behaviour and efficiency of the model.

## Test 1

```{r, run_algo_1_penalty, fig.width=9, fig.height=9}
global_vars <- new.env()
run_vars <- new.env()

my_points <- init_points()
my_paths <- init_paths()
visualise_paths()
run1 <- withSeed(find_path(max_runs = 50000, visit_penalty = 0.25))
plot_path(run1$best_route)
run1[1:(length(run1) - 1)]
```

And the error codes...

```{r, run_algo_1_penalty_errors, fig.width=9, fig.height=4}
library(ggplot2)
plot_error_codes(run1)
```

Well, that's much better! It's found a faster route (at least 3 times!) in under half the time it took the original model. Looking at the error codes, we also see that the overwhelming reason for run errors was because it had exceeded the maximum-allowed distance, rather than having visited a a waypoint too many times. Being that this is the case, we could even remove the parameter of maximum number of visits to a waypoint (max_visits). In more complex tasks where there are more waypoints/paths, this arbitrary number could impede the algorithm and now it appears that it might be able to decide on its own based on any successful routes it has discovered.

## Test 2

You might be wondering why I don't get the model to try and visit just one point each, and doing that by generating some permutations of possible paths, but as with these navigation races I like doing with my girlfriend, there are often a few waypoints that must be run down and returned; this may also be a sensible strategy sometimes. So as this is not a possibility, the model needs to have the sort of decision-making process it has.

So let's try it on the same set of points but with some different paths. Fortuitously, the second path generated gives us such a set up. This time it sets off from $I$. Note that $G$ is solely connected to $F$, as is $I$ to $C$, and $H$ to $I$, so waypoints will be visited multiple times. Notice also that there are fewer paths, and with fewer options the algorithm should, in theory, come about a solution faster. In future developments we will explore path complexity more generally, particularly in terms of computation time.

```{r, run_algo_2, fig.width=9, fig.height=9}
my_points <- init_points()
my_paths <- init_paths()
my_paths <- init_paths()
visualise_paths()
run2 <- withSeed(find_path(start_waypoint = "i", max_visits = 3, max_runs = 50000))
plot_path(run2$best_route)
run2[1:(length(run2) - 1)]
```

And we get similar proportions of error codes...

```{r, run_algo_2_errors, fig.width=9, fig.height=4}
plot_error_codes(run2)
```

## Conclusion

With a few simple tweaks, the algorithm is working much more efficiently. It is finding the shortest route and doing so much more quickly than in the first part of this series. Be sure to keep reading as we address path complexity and also get it working on real-world routes in which we will start introducing parameters of gradient, effort/stamina, etc., which are all important considerations when planning an orienteering race!